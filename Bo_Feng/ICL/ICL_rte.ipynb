{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6218fe27f7424aaeb82e5cc6c74f781e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8383e56853b347be8ba5d63d8aece978","IPY_MODEL_2abacaca0ed8451d9d4cb5eb20c11e1c","IPY_MODEL_d726399a7e644eb09a1228e1f85bd332"],"layout":"IPY_MODEL_9b1ad8dd8c8f4482810d10a18eef34a0"}},"8383e56853b347be8ba5d63d8aece978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2e4174428a34715a27d711b422d8b49","placeholder":"​","style":"IPY_MODEL_6c4a25550dcb4487afd748ea4be1b3d8","value":"Map: 100%"}},"2abacaca0ed8451d9d4cb5eb20c11e1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93da47a0a9564e85b0bafe540bd5b80f","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46f344483e4848689a67da0252a619f1","value":30000}},"d726399a7e644eb09a1228e1f85bd332":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03a99f20af2e4a00a4b0d85fc88d08f5","placeholder":"​","style":"IPY_MODEL_6ba654609a23469b83085f1299cb5f86","value":" 30000/30000 [00:05&lt;00:00, 6034.95 examples/s]"}},"9b1ad8dd8c8f4482810d10a18eef34a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2e4174428a34715a27d711b422d8b49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c4a25550dcb4487afd748ea4be1b3d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93da47a0a9564e85b0bafe540bd5b80f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f344483e4848689a67da0252a619f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03a99f20af2e4a00a4b0d85fc88d08f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ba654609a23469b83085f1299cb5f86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cd9c8b83d724723af03b9a261709758":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d976101fec34e2b9df5d2bd9c5cb4e2","IPY_MODEL_2d316408798d401ea5fed0ee56444885","IPY_MODEL_0176e48113dd4b129c8983f15e4f782b"],"layout":"IPY_MODEL_0b6a15dd63cc4303b1c5981c87d3d19e"}},"1d976101fec34e2b9df5d2bd9c5cb4e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39ab2887f38a4ffea8538843f7c6709f","placeholder":"​","style":"IPY_MODEL_d9e10093e074449b8c1412f81f83e1ff","value":"Filter: 100%"}},"2d316408798d401ea5fed0ee56444885":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e44afdf290743afb602d2cdc7a138f5","max":2490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc0c2ff8afb94f0f95d5be2aa443a359","value":2490}},"0176e48113dd4b129c8983f15e4f782b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a12bb64aac1047cfbd29f8fd1da5312e","placeholder":"​","style":"IPY_MODEL_511c9fcc765545b28cd6e502c414cb12","value":" 2490/2490 [00:00&lt;00:00, 54224.58 examples/s]"}},"0b6a15dd63cc4303b1c5981c87d3d19e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39ab2887f38a4ffea8538843f7c6709f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e10093e074449b8c1412f81f83e1ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e44afdf290743afb602d2cdc7a138f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc0c2ff8afb94f0f95d5be2aa443a359":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a12bb64aac1047cfbd29f8fd1da5312e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"511c9fcc765545b28cd6e502c414cb12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fc22c2f635f413799d3460e23416a0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a73a8d6b75643c7a4fe30935885289e","IPY_MODEL_caafcac99aa44d9895bc7523e5020137","IPY_MODEL_ad06cbf903bf49c68513b5b4290ee673"],"layout":"IPY_MODEL_37476dd2c6bf4f01971b7bf2bbf95825"}},"9a73a8d6b75643c7a4fe30935885289e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_673c1df05c8648ef9487a888abf13b0a","placeholder":"​","style":"IPY_MODEL_942e71c7f62842b88bf7a60341beea9a","value":"Map: 100%"}},"caafcac99aa44d9895bc7523e5020137":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42ee94b9bf7c4ba2993079ed129b4d5a","max":277,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b61fb673a9a14360977e12a559583587","value":277}},"ad06cbf903bf49c68513b5b4290ee673":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b07da5de25304b1e918498b6f1c92199","placeholder":"​","style":"IPY_MODEL_79da4bee25364c37ba73824a8b957aa7","value":" 277/277 [00:00&lt;00:00, 3422.27 examples/s]"}},"37476dd2c6bf4f01971b7bf2bbf95825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"673c1df05c8648ef9487a888abf13b0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"942e71c7f62842b88bf7a60341beea9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42ee94b9bf7c4ba2993079ed129b4d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b61fb673a9a14360977e12a559583587":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b07da5de25304b1e918498b6f1c92199":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79da4bee25364c37ba73824a8b957aa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efe2daf127b143c1bf3e6fcb02cc8419":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca77c8ec16c847b1957f086b583ae60e","IPY_MODEL_bcbbabc4478a41f8ba568ac0978e35a9","IPY_MODEL_c1dcd2c918e94b5ea0d7dc07f2321dfc"],"layout":"IPY_MODEL_9a039bd14c724d138ee2519914e9449a"}},"ca77c8ec16c847b1957f086b583ae60e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_714235e4a30e48cab3c7fab50dda41f3","placeholder":"​","style":"IPY_MODEL_5971be3566a24683928d1c06a257777c","value":"Map: 100%"}},"bcbbabc4478a41f8ba568ac0978e35a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4989168fa4384147bfdd064dcb314008","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14efed31ae2b4646af70eff549d4d75b","value":30000}},"c1dcd2c918e94b5ea0d7dc07f2321dfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79d25bc550894296b592cefbf3f9ac56","placeholder":"​","style":"IPY_MODEL_230a248f62fd4e6586ac69c90032d625","value":" 30000/30000 [00:07&lt;00:00, 3788.80 examples/s]"}},"9a039bd14c724d138ee2519914e9449a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714235e4a30e48cab3c7fab50dda41f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5971be3566a24683928d1c06a257777c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4989168fa4384147bfdd064dcb314008":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14efed31ae2b4646af70eff549d4d75b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79d25bc550894296b592cefbf3f9ac56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"230a248f62fd4e6586ac69c90032d625":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Intro: In-Context Learning Experiment"],"metadata":{"id":"UaJIlfndRx2s"}},{"cell_type":"markdown","source":["reference repo: https://github.com/uds-lsv/llmft/tree/main"],"metadata":{"id":"ohytlhJuR6gU"}},{"cell_type":"markdown","source":["- Experiment: In-Context Learning\n","- Model: opt-125M/350M\n","- Datasets: RTE for in-domain and HANS for out-of-domain\n","- vary on num of shots: 2, 32, 128\n","- prompt format: GPT type\n","```plain\n","{text1} question: {text2} Yes or No?\n","answer: [Yes/No]\n","```"],"metadata":{"id":"1rN6M82vqpcZ"}},{"cell_type":"markdown","source":["what does in-context learning (ICL) here mean:\n","\n","- Instead of updateing the pre-trained model's weight, ICL solve tasks by conditioning on a sequence of demonstrations (i.e. input _x_ and its ground truth _y_ combined by specific pattern).\n","\n","- ICL thus feeds the model a sequence of such demonstrations, followed by the test input (modified by applying the pattern transformation). The language model is then expected to predict the label of this final data point."],"metadata":{"id":"X6YEu5FFVa6p"}},{"cell_type":"markdown","source":["bash code for experiment: `bash $PROJECT_DIR/scripts/in_context/mnli/run_gpt3.sh rte 2 facebook/opt-30b 1 60000`\n","\n","- Task name: \"rte\"\n","- Number of shots: 2\n","- Model: facebook/opt-30b\n","- GPU: 1\n","- Port: 60000"],"metadata":{"id":"mC5-uJbdSB60"}},{"cell_type":"markdown","source":["Other Hyperparameters (all same as the original paper):\n","\n","- fixed context size: 2048 tokens"],"metadata":{"id":"uqIqlC_udpwh"}},{"cell_type":"markdown","source":["Experiment Process:\n","\n","- in-domain: we measure indomain generalization by measuring accuracy on the validation set of each dataset. So in this experiment, the demonstrations are from RTE's training dataset. And the test dataset is RTE's test one.\n","\n","- out-of-domain: we focus on generalization to challenge datasets, designed to test whether models adopt a particular heuristic, or make predictions based on spurious correlations during inference. So in this experiment, the demonstrations are also from RTE's training dataset. And And the test dataset is HANS validation dataset."],"metadata":{"id":"WzS_ZhUcUeqU"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-6oE5hnVfkB","outputId":"267e6e06-a215-4b66-a1c4-df4123563ce7","executionInfo":{"status":"ok","timestamp":1733953094675,"user_tz":300,"elapsed":2207,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/cs7643-group-project/notebooks"],"metadata":{"id":"vfn0qJLsg4wx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba120809-a98c-419e-c4fd-8c94bd5f1408","executionInfo":{"status":"ok","timestamp":1733953094678,"user_tz":300,"elapsed":70,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/cs7643-group-project/notebooks\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weZOPDg7hid7","outputId":"3eaaed2c-6bea-4948-8e31-e33d7e448004","executionInfo":{"status":"ok","timestamp":1733953094679,"user_tz":300,"elapsed":58,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["few_shot_context_distillation_mnli.ipynb        \u001b[0m\u001b[01;34moffload_folder\u001b[0m/\n","few_shot_context_distillation_rte.ipynb         \u001b[01;34mresults\u001b[0m/\n","few_shot_context_distillation_rts.ipynb         vanilla_cola_baseline.ipynb\n","few_shot_ICL_rte_baseline_results_opt-125M.csv  \u001b[01;34mwandb\u001b[0m/\n","ICL_rte.ipynb\n"]}]},{"cell_type":"code","source":["!pip install -q transformers accelerate bitsandbytes datasets"],"metadata":{"id":"bAhrMw3EmElS","executionInfo":{"status":"ok","timestamp":1733953097013,"user_tz":300,"elapsed":2371,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!export CUDA_LAUNCH_BLOCKING=1"],"metadata":{"id":"omsXp21jpTTD","executionInfo":{"status":"ok","timestamp":1733953097015,"user_tz":300,"elapsed":27,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Dependency and Config"],"metadata":{"id":"wuf84ZmXW4HB"}},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","import torch\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, EvalPrediction\n","from datasets import load_dataset, ClassLabel\n","import logging\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import numpy as np\n","\n","import time\n","import pandas as pd"],"metadata":{"id":"0b4AQE4gW_gk","executionInfo":{"status":"ok","timestamp":1733953104975,"user_tz":300,"elapsed":7980,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","\n","# for reproducibility\n","np.random.seed(42)\n","\n","torch.manual_seed(42)\n","\n","if torch.cuda.is_available():\n","  torch.cuda.manual_seed_all(42)"],"metadata":{"id":"s_MENoekXDrY","executionInfo":{"status":"ok","timestamp":1733953104976,"user_tz":300,"elapsed":69,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6M2FfpdXZAq","executionInfo":{"status":"ok","timestamp":1733953104977,"user_tz":300,"elapsed":68,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}},"outputId":"0d2b6309-d0df-46fe-99f0-cc5d4e008bd7"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Prep"],"metadata":{"id":"OfYLlcYlXOHl"}},{"cell_type":"code","source":["# originally in task_utils.py\n","task_to_keys = {\n","    # labels are: 0 (entailment), 1 (contradiction)\n","    \"rte\": (\"sentence1\", \"sentence2\"),\n","    \"mnli\": (\"premise\", \"hypothesis\"),\n","    \"mnli-original\": (\"premise\", \"hypothesis\"),\n","    \"mnli-mismatched\": (\"premise\", \"hypothesis\"),\n","    \"hans\": (\"premise\", \"hypothesis\"),\n","\n","    # labels are: 0 (not_duplicate), 1 (duplicate)\n","    \"qqp\": (\"question1\", \"question2\"),\n","    \"paws-qqp\": (\"sentence1\", \"sentence2\"),\n","\n","    # labels are: 0 (not acceptable), 1 (acceptable)\n","    \"cola\": (\"sentence\", None),\n","    \"cola-ood\": (\"sentence\", None),\n","}"],"metadata":{"id":"vgOFQMDskmmO","executionInfo":{"status":"ok","timestamp":1733953104978,"user_tz":300,"elapsed":65,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## In-Context Leearnig Data Preprocess"],"metadata":{"id":"pX3qvIRNxqQP"}},{"cell_type":"code","source":["def _select_subset_by_ids(dataset, indices):\n","  # originally in eval_utils.py\n","    subset = dataset.select(indices)\n","    return subset"],"metadata":{"id":"1g7iX_sRkWse","executionInfo":{"status":"ok","timestamp":1733953104979,"user_tz":300,"elapsed":64,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_balanced_subsets(dataset):\n","  # originally in eval_utils.py\n","    subset_per_label = {}\n","    for label_idx, _ in enumerate(dataset.features[\"label\"].names):\n","        subset_per_label[label_idx] = dataset.filter(\n","            lambda s: s[\"label\"] == label_idx)\n","    return subset_per_label"],"metadata":{"id":"ddM_IP4NgJ1W","executionInfo":{"status":"ok","timestamp":1733953104980,"user_tz":300,"elapsed":64,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def _select_random_subset(dataset, num_shots, balanced: bool, seed: int):\n","  # originally in eval_utils.py\n","    # fix seed\n","    np.random.seed(seed)\n","\n","    if num_shots < 1:\n","        return [], []\n","\n","    if balanced:\n","        assert num_shots % 2 == 0, \"a balanced context requires at least one demonstartion per label\"\n","        # select the same number of samples from every label\n","        indices = []  # we collect all indices here\n","        subset_per_label = get_balanced_subsets(dataset)\n","\n","        for _, samples in subset_per_label.items():\n","            subset_indices = samples[\"idx\"]\n","            # select num_shots // 2 samples\n","            subset_indices = np.random.choice(\n","                subset_indices, size=num_shots // 2, replace=False)\n","            indices += list(subset_indices)\n","        assert len(indices) == num_shots\n","    else:\n","        # just select a random subset of samples\n","        indices = np.random.choice(\n","            range(len(dataset)), size=num_shots, replace=False)\n","\n","    # return _select_subset_by_ids(dataset, indices), indices\n","    return _select_subset_by_idx(dataset, indices), indices"],"metadata":{"id":"beoKymzZiyOL","executionInfo":{"status":"ok","timestamp":1733953104981,"user_tz":300,"elapsed":64,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def _select_subset_by_idx(dataset, indices):\n","  # originally in eval_utils.py\n","    dataset = dataset.filter(\n","        lambda s: s[\"idx\"] in indices)\n","    return dataset"],"metadata":{"id":"CJ6hmn3Uj2mG","executionInfo":{"status":"ok","timestamp":1733953104982,"user_tz":300,"elapsed":64,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def create_few_shot_context(\n","    dataset_name,\n","    dataset,\n","    num_shots,\n","    pattern,\n","    label_to_tokens,\n","    separate_shots_by=\" \",\n","    description=\"\",\n","    target_prefix=\"\",\n","    from_indices=None,\n","    balanced=False,\n","    shuffle=False,\n","    seed=123\n","):\n","    assert pattern is not None\n","    assert label_to_tokens is not None\n","\n","    # select samples from which the context will be constructed\n","    if from_indices is not None:\n","        demonstrations, indices = _select_subset_by_ids(dataset, from_indices)\n","    else:\n","        demonstrations, indices = _select_random_subset(\n","            dataset, num_shots, balanced, seed)\n","\n","    if shuffle:\n","        if len(demonstrations) > 0:\n","            demonstrations = demonstrations.shuffle(seed)\n","\n","    # create context\n","    context = \"\" if description == \"\" else f\"{description}{separate_shots_by}\"\n","\n","    for sample in demonstrations:\n","        formated_sample = pattern.format(\n","            text1=sample[task_to_keys[dataset_name][0]],\n","            text2=sample[task_to_keys[dataset_name][1]\n","                         ] if task_to_keys[dataset_name][1] is not None else None\n","        )\n","        verbalized_label = label_to_tokens[sample[\"label\"]]\n","        if verbalized_label.startswith(\"Ä \"):\n","            # we need to remove the leading whitespace from the target token in the context\n","            verbalized_label = verbalized_label[1:]\n","        elif verbalized_label.startswith(\"â\"):\n","            # we need to remove the leading whitespace from the target token in the context\n","            verbalized_label = verbalized_label[1:]\n","\n","        context += f\"{formated_sample}{target_prefix}{verbalized_label}{separate_shots_by}\"\n","\n","    return context, indices"],"metadata":{"id":"EdHVOkxyhcIs","executionInfo":{"status":"ok","timestamp":1733953104983,"user_tz":300,"elapsed":64,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def add_context_to_dataset(dataset_name, dataset, pattern, context):\n","    def _add_context(samples):\n","        result = {}\n","        modified_inputs = []\n","        key1, key2 = task_to_keys[dataset_name]\n","\n","        for idx in range(len(samples[key1])):\n","            modified_input = f\"{context}{pattern.format(text1=samples[key1][idx], text2=samples[key2][idx])}\"\n","            modified_inputs.append(modified_input)\n","\n","        result[\"modified_input\"] = modified_inputs\n","\n","        return result\n","\n","    dataset = dataset.map(_add_context, batched=True, batch_size=8)\n","\n","    return dataset\n"],"metadata":{"id":"Us-Bc2MyE0mu","executionInfo":{"status":"ok","timestamp":1733953104984,"user_tz":300,"elapsed":64,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Result Processing"],"metadata":{"id":"CEN3POMr0gP9"}},{"cell_type":"code","source":["def simple_accuracy(preds, labels):\n","    \"\"\"\n","    Calculate simple accuracy metric.\n","\n","    Args:\n","        preds (np.ndarray): Predictions array\n","        labels (np.ndarray): Ground truth labels array\n","\n","    Returns:\n","        float: Accuracy score\n","    \"\"\"\n","    return float((preds == labels).mean())"],"metadata":{"id":"b5BawESlXUdb","executionInfo":{"status":"ok","timestamp":1733953104985,"user_tz":300,"elapsed":65,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(predictions, labels):\n","    \"\"\"\n","    Compute evaluation metrics for model predictions.\n","\n","    Args:\n","        predictions (List[int]): List of model predictions\n","        labels (List[int]): List of true labels\n","\n","    Returns:\n","        dict: Dictionary containing the computed metrics\n","    \"\"\"\n","    # Convert predictions and labels to numpy arrays if they aren't already\n","    predictions = np.array(predictions)\n","    labels = np.array(labels)\n","\n","    # For RTE and HANS tasks, we use simple accuracy as the metric\n","    # This aligns with the GLUE metric implementation for these tasks\n","    accuracy = simple_accuracy(predictions, labels)\n","\n","    return {\n","        \"accuracy\": accuracy\n","    }\n"],"metadata":{"id":"Fir4RmXZXSFd","executionInfo":{"status":"ok","timestamp":1733953104986,"user_tz":300,"elapsed":65,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Run Experiment"],"metadata":{"id":"JNLlONqZVC0Q"}},{"cell_type":"code","source":["# Configuration\n","seed = 42\n","model_name = \"facebook/opt-125m\"\n","task_name = \"rte\"\n","\n","# set prompt pattern\n","pattern = \"{text1} question: {text2} Yes or No?\"\n","target_tokens = [\"Ä Yes\", \"Ä No\"] # Using Ä as special token\n","target_prefix = \" answer: \"\n","separate_shots_by = \"\\n\\n\"\n","\n","num_shots = [2, 32, 128]  # Number of few-shot examples\n","\n","# Load datasets\n","train_dataset = load_dataset(\"glue\", task_name, split=\"train\")\n","eval_datasets = {\"rte\": load_dataset(\"glue\", \"rte\", split=\"validation\"),\n","                 \"hans\": load_dataset(\"hans\", split=\"validation\")}\n","\n","# Initialize model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model.to(device)\n","\n","# initialize results\n","results = {}\n","\n","\n","# In-Context Learning Setup:\n","for n in num_shots:\n","    print(f\"---- start with num of shots: {n} ---\")\n","    # Create prompt with examples of num_shots\n","    context, context_indices = create_few_shot_context(\n","        dataset_name=task_name,\n","        dataset=train_dataset,\n","        num_shots=n,\n","        pattern=pattern,\n","        label_to_tokens={0: \"No\", 1: \"Yes\"},\n","        separate_shots_by=separate_shots_by,\n","        target_prefix=target_prefix,\n","        balanced=True,\n","        shuffle=True\n","    )\n","\n","    # Add context to evaluation dataset\n","    for eval_task_name, eval_dataset in eval_datasets.items():\n","      print(\"eval task name: \", eval_task_name)\n","      eval_dataset_with_context = add_context_to_dataset(\n","          dataset_name=eval_task_name,\n","          dataset=eval_dataset,\n","          pattern=pattern,\n","          context=context\n","      )\n","\n","      # Evaluation loop\n","      model.eval()\n","      predictions = []\n","      labels = []\n","\n","      with torch.no_grad():\n","          for example in eval_dataset_with_context:\n","              # Tokenize input\n","              inputs = tokenizer(\n","                  example[\"modified_input\"] + target_prefix,\n","                  return_tensors=\"pt\",\n","                  truncation=True,\n","                  max_length=1024\n","              ).to(device)\n","\n","              # Get model predictions\n","              outputs = model.generate(\n","                  **inputs,\n","                  max_new_tokens=5,\n","                  num_return_sequences=1,\n","                  pad_token_id=tokenizer.eos_token_id\n","              )\n","\n","              # Decode prediction\n","              pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","              pred = 1 if \"Yes\" in pred_text else 0\n","\n","              predictions.append(pred)\n","              labels.append(example[\"label\"])\n","\n","      # Compute metrics\n","      metrics = compute_metrics(predictions, labels)\n","\n","      # Initialize results structure if needed\n","      if eval_task_name not in results:\n","          results[eval_task_name] = {}\n","      if n not in results[eval_task_name]:\n","          results[eval_task_name][n] = []\n","\n","      results[eval_task_name][n].append(metrics)\n","\n","      print(f\"Num shots: {n}\")  # Changed to n\n","      print(f\"Accuracy: {metrics['accuracy']}\")"],"metadata":{"id":"FQ2rCY9Hbnjp","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6218fe27f7424aaeb82e5cc6c74f781e","8383e56853b347be8ba5d63d8aece978","2abacaca0ed8451d9d4cb5eb20c11e1c","d726399a7e644eb09a1228e1f85bd332","9b1ad8dd8c8f4482810d10a18eef34a0","b2e4174428a34715a27d711b422d8b49","6c4a25550dcb4487afd748ea4be1b3d8","93da47a0a9564e85b0bafe540bd5b80f","46f344483e4848689a67da0252a619f1","03a99f20af2e4a00a4b0d85fc88d08f5","6ba654609a23469b83085f1299cb5f86","0cd9c8b83d724723af03b9a261709758","1d976101fec34e2b9df5d2bd9c5cb4e2","2d316408798d401ea5fed0ee56444885","0176e48113dd4b129c8983f15e4f782b","0b6a15dd63cc4303b1c5981c87d3d19e","39ab2887f38a4ffea8538843f7c6709f","d9e10093e074449b8c1412f81f83e1ff","1e44afdf290743afb602d2cdc7a138f5","fc0c2ff8afb94f0f95d5be2aa443a359","a12bb64aac1047cfbd29f8fd1da5312e","511c9fcc765545b28cd6e502c414cb12","9fc22c2f635f413799d3460e23416a0b","9a73a8d6b75643c7a4fe30935885289e","caafcac99aa44d9895bc7523e5020137","ad06cbf903bf49c68513b5b4290ee673","37476dd2c6bf4f01971b7bf2bbf95825","673c1df05c8648ef9487a888abf13b0a","942e71c7f62842b88bf7a60341beea9a","42ee94b9bf7c4ba2993079ed129b4d5a","b61fb673a9a14360977e12a559583587","b07da5de25304b1e918498b6f1c92199","79da4bee25364c37ba73824a8b957aa7","efe2daf127b143c1bf3e6fcb02cc8419","ca77c8ec16c847b1957f086b583ae60e","bcbbabc4478a41f8ba568ac0978e35a9","c1dcd2c918e94b5ea0d7dc07f2321dfc","9a039bd14c724d138ee2519914e9449a","714235e4a30e48cab3c7fab50dda41f3","5971be3566a24683928d1c06a257777c","4989168fa4384147bfdd064dcb314008","14efed31ae2b4646af70eff549d4d75b","79d25bc550894296b592cefbf3f9ac56","230a248f62fd4e6586ac69c90032d625"]},"executionInfo":{"status":"error","timestamp":1733959935621,"user_tz":300,"elapsed":1048830,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}},"outputId":"6d184ae5-7e0f-429f-b301-fcd57ea30296"},"execution_count":18,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub\n","WARNING:datasets.load:Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub\n","Found the latest cached dataset configuration 'rte' at /root/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Wed Dec 11 21:31:48 2024).\n","WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'rte' at /root/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Wed Dec 11 21:31:48 2024).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["---- start with num of shots: 2 ---\n","eval task name:  rte\n","Num shots: 2\n","Accuracy: 0.4729241877256318\n","eval task name:  hans\n","Num shots: 2\n","Accuracy: 0.5\n","---- start with num of shots: 32 ---\n","eval task name:  rte\n","Num shots: 32\n","Accuracy: 0.4729241877256318\n","eval task name:  hans\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6218fe27f7424aaeb82e5cc6c74f781e","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["Num shots: 32\n","Accuracy: 0.5\n","---- start with num of shots: 128 ---\n"]},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/2490 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd9c8b83d724723af03b9a261709758"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval task name:  rte\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/277 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc22c2f635f413799d3460e23416a0b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Num shots: 128\n","Accuracy: 0.4729241877256318\n","eval task name:  hans\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe2daf127b143c1bf3e6fcb02cc8419"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-b7216421a27b>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m               \u001b[0;31m# Get model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m               outputs = model.generate(\n\u001b[0m\u001b[1;32m     71\u001b[0m                   \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                   \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2216\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/opt/modeling_opt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, position_ids)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         outputs = self.model.decoder(\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/opt/modeling_opt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, position_ids)\u001b[0m\n\u001b[1;32m    931\u001b[0m                 )\n\u001b[1;32m    932\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    934\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/opt/modeling_opt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, past_key_value, output_attentions, use_cache, position_ids)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/opt/modeling_opt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions, position_ids)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;31m# self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["results"],"metadata":{"id":"Yo4a8_1FbnrW","executionInfo":{"status":"aborted","timestamp":1733959935624,"user_tz":300,"elapsed":4,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(results).to_csv(f\"./few_shot_ICL_rte_baseline_results_{model_name}.csv\")"],"metadata":{"id":"WcjBXs2cbno-","executionInfo":{"status":"aborted","timestamp":1733959935625,"user_tz":300,"elapsed":4,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a5IDQ8X11veg","executionInfo":{"status":"aborted","timestamp":1733959935627,"user_tz":300,"elapsed":6,"user":{"displayName":"Bo Feng","userId":"14786095707414123602"}}},"execution_count":null,"outputs":[]}]}